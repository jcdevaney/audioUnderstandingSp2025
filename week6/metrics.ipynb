{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcdevaney/audioUnderstandingSp2025/blob/main/week6/metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries and Data"
      ],
      "metadata": {
        "id": "c5bCMTrcDRgu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8-J1PK9CAYcS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d785d6f-cc88-4f12-8929-89b611341557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==1.4\n",
            "  Downloading scikit_learn-1.4.0-1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.4) (3.5.0)\n",
            "Downloading scikit_learn-1.4.0-1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "Successfully installed scikit-learn-1.4.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "!pip install -U scikit-learn==1.4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data"
      ],
      "metadata": {
        "id": "mjLTnFYdDWMO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Iris Dataset for Classification"
      ],
      "metadata": {
        "id": "WvyJ_a-4Ndqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import Iris dataset\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()"
      ],
      "metadata": {
        "id": "Vqyg-_rStqpw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## California Housing Data for Regression"
      ],
      "metadata": {
        "id": "QhLc_DqzNU0Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WuiE5k4iAYcX"
      },
      "outputs": [],
      "source": [
        "# Import the California Housing Data from used in the HOML book, Chapter 2\n",
        "\n",
        "import os\n",
        "import tarfile\n",
        "import urllib\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "    os.makedirs(housing_path, exist_ok=True)\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UtrQV8-WAYcX"
      },
      "outputs": [],
      "source": [
        "fetch_housing_data()\n",
        "\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "    return pd.read_csv(csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KYoU5UmBAYcY"
      },
      "outputs": [],
      "source": [
        "housing = load_housing_data()\n",
        "y = housing['median_house_value']\n",
        "X = housing.drop(['median_house_value','ocean_proximity','total_bedrooms'],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing/training split"
      ],
      "metadata": {
        "id": "zcfiuFK_rkci"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JeaAdAy6AYcb"
      },
      "outputs": [],
      "source": [
        "# Use stratify split works for the iris dataset\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in split.split(iris.data, iris.target):\n",
        "    X_iris_train = iris.data[train_index]\n",
        "    X_iris_test = iris.data[test_index]\n",
        "    y_iris_train = iris.target[train_index]\n",
        "    y_iris_test = iris.target[test_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dAGxZ3_PAYca"
      },
      "outputs": [],
      "source": [
        "# Use regular split for the housing dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split data and labels into a training and a test set\n",
        "X_train, X_test, y_housing_train, y_housing_test = train_test_split(X, y, random_state=0, stratify=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "G7zF17C_AYch"
      },
      "outputs": [],
      "source": [
        "# Use a mean imputer to replace missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imp_mean.fit(X_train)\n",
        "SimpleImputer()\n",
        "# apply to both the testing and training data\n",
        "X_housing_train = imp_mean.transform(X_train)\n",
        "X_housing_test = imp_mean.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metrics"
      ],
      "metadata": {
        "id": "dvpeAwOYtoyr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification"
      ],
      "metadata": {
        "id": "KjwjZwqfPWeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import KNN clasifier and fit to training data\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "knn.fit(X_iris_train, y_iris_train)\n",
        "\n",
        "# generate list of predictions\n",
        "y_iris_pred = knn.predict(X_iris_test)"
      ],
      "metadata": {
        "id": "wGtXpSaSwmXl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a confusion matrix on iris data\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(y_iris_test, y_iris_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lG_tbUBb3CfL",
        "outputId": "8ef25891-cbc6-4728-87ca-06df626b5b55"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10,  0,  0],\n",
              "       [ 0, 10,  0],\n",
              "       [ 0,  1,  9]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate class-wise precision score on iris data\n",
        "from sklearn.metrics import precision_score\n",
        "precision_score(y_iris_test, y_iris_pred, average=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlLKl1iwxOBV",
        "outputId": "2e9d8d09-0121-4124-932e-c2442925b50f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.90909091, 1.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate class-wise recall score on iris data\n",
        "from sklearn.metrics import recall_score\n",
        "recall_score(y_iris_test, y_iris_pred, average=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hRe8u0XxySA",
        "outputId": "b16207ab-e3b9-4db7-fcf1-85effa73c1b0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1. , 1. , 0.9])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate overall and class-wise F1-score on iris data\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
        "print(f1_score(y_iris_test, y_iris_pred, average='micro'))\n",
        "# Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
        "print(f1_score(y_iris_test, y_iris_pred, average='macro'))\n",
        "# Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.\n",
        "print(f1_score(y_iris_test, y_iris_pred, average='weighted'))\n",
        "\n",
        "# Class-wise, no averaging\n",
        "print(f1_score(y_iris_test, y_iris_pred, average=None))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukMVCaxD4SAw",
        "outputId": "4f35eb44-8025-46d7-bf9c-ce3349ad3e23"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9666666666666667\n",
            "0.9665831244778613\n",
            "0.9665831244778613\n",
            "[1.         0.95238095 0.94736842]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate AUC score (ROC implementation in scikit-learn only works for binary classification) on iris data\n",
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_iris_test, knn.predict_proba(X_iris_test), multi_class='ovr')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFwx28Ocx9dB",
        "outputId": "56c67d0a-91df-4b08-f3d2-c0af2cd204f6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.975"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression"
      ],
      "metadata": {
        "id": "CFjepZ8CQFzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# instantiate a model and fit it to the training set\n",
        "linreg = LinearRegression().fit(X_housing_train, y_housing_train)\n",
        "\n",
        "# generate list of predictions\n",
        "y_housing_pred=linreg.predict(X_housing_test)"
      ],
      "metadata": {
        "id": "o8CSLYlMQGBM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate RMSE on housing data\n",
        "from sklearn.metrics import root_mean_squared_error\n",
        "\n",
        "root_mean_squared_error(y_housing_test, y_housing_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ztCVjwjy_0p",
        "outputId": "1729c421-1184-487f-90f5-0e9388a2d6dd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70639.47198102309"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate MAE on housing data\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "y_pred=linreg.predict(X_housing_test)\n",
        "\n",
        "mean_absolute_error(y_housing_test, y_housing_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPcTijMZ14Vc",
        "outputId": "7f6d9470-97cd-44ed-a190-8a867ca14ab7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51604.687324832186"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "c5bCMTrcDRgu"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}